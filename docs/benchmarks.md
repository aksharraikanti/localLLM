# Inference & Quantization Benchmarks

## Quantization Stats

- Model directory: `models/quantized/8bit_model`
- Size on disk: *TBD*
- Memory footprint (GPU/CPU): *TBD*

## Inference Latencies

Benchmark ONNX vs PyTorch on 20 sample prompts. Record average latencies:

| Engine     | Avg latency (ms) |
|------------|------------------|
| PyTorch    | TBD              |
| ONNXRuntime| TBD              |

## FlashAttention Speedup

- FlashAttention enabled via `flash_attn_unpadded`: TBDÃ— speedup

Documentation and charts to be added as experiments complete.
